{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPL5SK4DCOkeOKW53XhOQkT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rajdeep7102/Rajdeep7102/blob/main/face_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "06znrCi1-Hu9"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "# Unzip our data\n",
        "zip_ref = zipfile.ZipFile(\"/content/Face-Images.zip\",\"r\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Walk through Face-Images directory and list number of files\n",
        "for dirpath, dirnames, filenames in os.walk(\"Face-Images\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "id": "R6-fC0B9AU-_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TrainingImagePath = 'Face Images//Final Training Images'"
      ],
      "metadata": {
        "id": "FMUWynu0_YM-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cRluKqycI_ZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        shear_range=0.1,\n",
        "        zoom_range=0.1,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "# Defining pre-processing transformations on raw images of testing data\n",
        "# No transformations are done on the testing images\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create an augmented data generator instance\n",
        "train_datagen_augmented = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255.,\n",
        "                                             rotation_range=0.2,\n",
        "                                             width_shift_range=0.2,\n",
        "                                             height_shift_range=0.2,\n",
        "                                             zoom_range=0.2,\n",
        "                                             horizontal_flip=True)\n",
        "\n",
        "# Generating the Training Data\n",
        "training_set = train_datagen_augmented.flow_from_directory(\n",
        "        TrainingImagePath,\n",
        "        target_size=(64, 64),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "# Generating the Testing Data\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "        TrainingImagePath,\n",
        "        target_size=(64, 64),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "# Printing class labels for each face\n",
        "test_set.class_indices\n"
      ],
      "metadata": {
        "id": "6-tCTH4jAogC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = train_datagen_augmented.flow_from_directory(TrainingImagePath,target_size=(64,64),batch_size=32,class_mode='categorical')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory(TrainingImagePath,target_size=(64,64),batch_size=32,\n",
        "                                            class_mode='categorical')\n",
        "\n",
        "test_set.class_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZN751ruvAyPj",
        "outputId": "67369c0a-af9e-42e8-8af2-e79927b108ed"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 244 images belonging to 16 classes.\n",
            "Found 244 images belonging to 16 classes.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'face1': 0,\n",
              " 'face10': 1,\n",
              " 'face11': 2,\n",
              " 'face12': 3,\n",
              " 'face13': 4,\n",
              " 'face14': 5,\n",
              " 'face15': 6,\n",
              " 'face16': 7,\n",
              " 'face2': 8,\n",
              " 'face3': 9,\n",
              " 'face4': 10,\n",
              " 'face5': 11,\n",
              " 'face6': 12,\n",
              " 'face7': 13,\n",
              " 'face8': 14,\n",
              " 'face9': 15}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TrainClasses = training_set.class_indices\n",
        "\n",
        "ResultMap={}\n",
        "for faceValue, faceName in zip(TrainClasses.values(),TrainClasses.keys()):\n",
        "  ResultMap[faceValue]=faceName\n",
        "\n",
        "import pickle\n",
        "with open(\"ResultsMap.pkl\",'wb') as fileWriteStream:\n",
        "  pickle.dump(ResultMap,fileWriteStream)\n",
        "\n",
        "print(\"Mapping of face and its ID\",ResultMap)\n",
        "\n",
        "OutputNeurons=len(ResultMap)\n",
        "print('\\n The Number of output neurons: ', OutputNeurons)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g76JM66UB09p",
        "outputId": "bdf86f7f-957c-45c1-8db7-d61ec738f977"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapping of face and its ID {0: 'face1', 1: 'face10', 2: 'face11', 3: 'face12', 4: 'face13', 5: 'face14', 6: 'face15', 7: 'face16', 8: 'face2', 9: 'face3', 10: 'face4', 11: 'face5', 12: 'face6', 13: 'face7', 14: 'face8', 15: 'face9'}\n",
            "\n",
            " The Number of output neurons:  16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''######################## Create CNN deep learning model ########################'''\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPool2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "\n",
        "'''Initializing the Convolutional Neural Network'''\n",
        "classifier= Sequential()\n",
        "\n",
        "''' STEP--1 Convolution\n",
        "# Adding the first layer of CNN\n",
        "# we are using the format (64,64,3) because we are using TensorFlow backend\n",
        "# It means 3 matrix of size (64X64) pixels representing Red, Green and Blue components of pixels\n",
        "'''\n",
        "classifier.add(Convolution2D(32, kernel_size=(5, 5), strides=(1, 1), input_shape=(64,64,3), activation='relu'))\n",
        "\n",
        "'''# STEP--2 MAX Pooling'''\n",
        "classifier.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "'''############## ADDITIONAL LAYER of CONVOLUTION for better accuracy #################'''\n",
        "classifier.add(Convolution2D(64, kernel_size=(5, 5), strides=(1, 1), activation='relu'))\n",
        "\n",
        "classifier.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "'''# STEP--3 FLattening'''\n",
        "classifier.add(Flatten())\n",
        "\n",
        "'''# STEP--4 Fully Connected Neural Network'''\n",
        "classifier.add(Dense(64, activation='relu'))\n",
        "\n",
        "classifier.add(Dense(OutputNeurons, activation='softmax'))\n",
        "\n",
        "'''# Compiling the CNN'''\n",
        "#classifier.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "classifier.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=[\"accuracy\"])\n",
        "\n",
        "###########################################################\n",
        "import time\n",
        "# Measuring the time taken by the model to train\n",
        "StartTime=time.time()\n",
        "\n",
        "# Starting the model training\n",
        "classifier.fit_generator(\n",
        "                    training_set,\n",
        "                    steps_per_epoch=8,\n",
        "                    epochs=100,\n",
        "                    validation_data=test_set,\n",
        "                    validation_steps=10)\n",
        "\n",
        "EndTime=time.time()\n",
        "print(\"###### Total Time Taken: \", round((EndTime-StartTime)/60), 'Minutes ######')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOsIMYXcCU3y",
        "outputId": "5caa528a-9438-4345-a1da-2b235b794b71"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-b0c303e2d1c4>:44: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  classifier.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - ETA: 0s - loss: 2.8110 - accuracy: 0.0533"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r8/8 [==============================] - 5s 457ms/step - loss: 2.8110 - accuracy: 0.0533 - val_loss: 23.6183 - val_accuracy: 0.0656\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 4s 443ms/step - loss: 2.7722 - accuracy: 0.0697\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 3s 299ms/step - loss: 2.7535 - accuracy: 0.0820\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 3s 291ms/step - loss: 2.7197 - accuracy: 0.0861\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 3s 297ms/step - loss: 2.6964 - accuracy: 0.1230\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 3s 299ms/step - loss: 2.6592 - accuracy: 0.1680\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 3s 298ms/step - loss: 2.5462 - accuracy: 0.1475\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 3s 294ms/step - loss: 2.4423 - accuracy: 0.2459\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 3s 349ms/step - loss: 2.2752 - accuracy: 0.2418\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 4s 396ms/step - loss: 2.3327 - accuracy: 0.2377\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 3s 292ms/step - loss: 2.2723 - accuracy: 0.3402\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 3s 295ms/step - loss: 2.1315 - accuracy: 0.3279\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 3s 322ms/step - loss: 2.0098 - accuracy: 0.3443\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 3s 374ms/step - loss: 2.0158 - accuracy: 0.3115\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 3s 307ms/step - loss: 1.9412 - accuracy: 0.3648\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 3s 301ms/step - loss: 1.8191 - accuracy: 0.3934\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 3s 301ms/step - loss: 1.8412 - accuracy: 0.4057\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 3s 299ms/step - loss: 1.7489 - accuracy: 0.4631\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 3s 425ms/step - loss: 1.8164 - accuracy: 0.3893\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 3s 335ms/step - loss: 1.7011 - accuracy: 0.4426\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 3s 296ms/step - loss: 1.6557 - accuracy: 0.4180\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 3s 443ms/step - loss: 1.6261 - accuracy: 0.4549\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 3s 322ms/step - loss: 1.4620 - accuracy: 0.5123\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 3s 292ms/step - loss: 1.3254 - accuracy: 0.6025\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 3s 303ms/step - loss: 1.3496 - accuracy: 0.5492\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 4s 497ms/step - loss: 1.4077 - accuracy: 0.5369\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 3s 305ms/step - loss: 1.4501 - accuracy: 0.4877\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 3s 298ms/step - loss: 1.3429 - accuracy: 0.5328\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 3s 295ms/step - loss: 1.3697 - accuracy: 0.5451\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 4s 447ms/step - loss: 1.2364 - accuracy: 0.6066\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 3s 305ms/step - loss: 1.2800 - accuracy: 0.5656\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 3s 306ms/step - loss: 1.3063 - accuracy: 0.5984\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 3s 302ms/step - loss: 1.2139 - accuracy: 0.5779\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 4s 492ms/step - loss: 1.1996 - accuracy: 0.5984\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 3s 298ms/step - loss: 1.2279 - accuracy: 0.5697\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 3s 303ms/step - loss: 1.1294 - accuracy: 0.6352\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 3s 290ms/step - loss: 1.0122 - accuracy: 0.6844\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 3s 332ms/step - loss: 0.9756 - accuracy: 0.6803\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 4s 448ms/step - loss: 1.0157 - accuracy: 0.6598\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 3s 327ms/step - loss: 0.9101 - accuracy: 0.7131\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 3s 299ms/step - loss: 0.9129 - accuracy: 0.7131\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 3s 303ms/step - loss: 0.8173 - accuracy: 0.7582\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 3s 300ms/step - loss: 0.8790 - accuracy: 0.7090\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 3s 408ms/step - loss: 1.0267 - accuracy: 0.7008\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 3s 369ms/step - loss: 1.0490 - accuracy: 0.6393\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 3s 289ms/step - loss: 0.8177 - accuracy: 0.7623\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 3s 298ms/step - loss: 0.7595 - accuracy: 0.7459\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 3s 312ms/step - loss: 0.7400 - accuracy: 0.7172\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 4s 502ms/step - loss: 0.7828 - accuracy: 0.7336\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 3s 301ms/step - loss: 0.8284 - accuracy: 0.7336\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 3s 295ms/step - loss: 0.8344 - accuracy: 0.7213\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 4s 459ms/step - loss: 0.7045 - accuracy: 0.7459\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 3s 293ms/step - loss: 0.6841 - accuracy: 0.7705\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 3s 294ms/step - loss: 0.7298 - accuracy: 0.7869\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 3s 297ms/step - loss: 0.6590 - accuracy: 0.7951\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 4s 438ms/step - loss: 0.7698 - accuracy: 0.7377\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 3s 305ms/step - loss: 0.7411 - accuracy: 0.7377\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 3s 298ms/step - loss: 0.7055 - accuracy: 0.7623\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 4s 443ms/step - loss: 0.7552 - accuracy: 0.7705\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 3s 296ms/step - loss: 0.6232 - accuracy: 0.8115\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 4s 373ms/step - loss: 0.6503 - accuracy: 0.7869\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 5s 705ms/step - loss: 0.6425 - accuracy: 0.7828\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 3s 304ms/step - loss: 0.6343 - accuracy: 0.7910\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 3s 332ms/step - loss: 0.6274 - accuracy: 0.8238\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 3s 295ms/step - loss: 0.5870 - accuracy: 0.8279\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 3s 300ms/step - loss: 0.6390 - accuracy: 0.7910\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 3s 298ms/step - loss: 0.4795 - accuracy: 0.8484\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 3s 319ms/step - loss: 0.5810 - accuracy: 0.8115\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 3s 317ms/step - loss: 1.0269 - accuracy: 0.7131\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 3s 296ms/step - loss: 0.7982 - accuracy: 0.7418\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 4s 478ms/step - loss: 0.5718 - accuracy: 0.8074\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 3s 297ms/step - loss: 0.6381 - accuracy: 0.7951\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 3s 297ms/step - loss: 0.5412 - accuracy: 0.8197\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 3s 322ms/step - loss: 0.5691 - accuracy: 0.8115\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 3s 341ms/step - loss: 0.5159 - accuracy: 0.8279\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 4s 401ms/step - loss: 0.4626 - accuracy: 0.8607\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 3s 300ms/step - loss: 0.4268 - accuracy: 0.8770\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 3s 322ms/step - loss: 0.5211 - accuracy: 0.8279\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 3s 305ms/step - loss: 0.5817 - accuracy: 0.8402\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 3s 297ms/step - loss: 0.4635 - accuracy: 0.8484\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 4s 517ms/step - loss: 0.5272 - accuracy: 0.8484\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 3s 298ms/step - loss: 0.5103 - accuracy: 0.8320\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 3s 299ms/step - loss: 0.4832 - accuracy: 0.8279\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 3s 296ms/step - loss: 0.5276 - accuracy: 0.8402\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 3s 366ms/step - loss: 0.4461 - accuracy: 0.8566\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 3s 421ms/step - loss: 0.4027 - accuracy: 0.8770\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 3s 301ms/step - loss: 0.3370 - accuracy: 0.8770\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 3s 306ms/step - loss: 0.3762 - accuracy: 0.8893\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 3s 355ms/step - loss: 0.3256 - accuracy: 0.9057\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 3s 297ms/step - loss: 0.4044 - accuracy: 0.8525\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 3s 308ms/step - loss: 0.3907 - accuracy: 0.9057\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 3s 422ms/step - loss: 0.3660 - accuracy: 0.8689\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 3s 323ms/step - loss: 0.2937 - accuracy: 0.9016\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 3s 302ms/step - loss: 0.3896 - accuracy: 0.8648\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 3s 305ms/step - loss: 0.3960 - accuracy: 0.8852\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 3s 300ms/step - loss: 0.4630 - accuracy: 0.8566\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 3s 296ms/step - loss: 0.3552 - accuracy: 0.8852\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 3s 357ms/step - loss: 0.4639 - accuracy: 0.8443\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 3s 304ms/step - loss: 0.3830 - accuracy: 0.8566\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 3s 304ms/step - loss: 0.4515 - accuracy: 0.8566\n",
            "###### Total Time Taken:  6 Minutes ######\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "\n",
        "ImagePath = '/content/Face Images/Final Testing Images/face14/4face4.jpg'\n",
        "test_image = image.load_img(ImagePath,target_size=(64,64))\n",
        "test_image=image.img_to_array(test_image)\n",
        "test_image=np.expand_dims(test_image,axis=0)\n",
        "result = classifier.predict(test_image,verbose=0)\n",
        "print('Prediction is:',ResultMap[np.argmax(result)])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r270j5SYC8A9",
        "outputId": "6ec5be4f-8b9b-4851-849f-e0b43d71d896"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction is: face14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oyKyCmjRIL_A"
      },
      "execution_count": 44,
      "outputs": []
    }
  ]
}